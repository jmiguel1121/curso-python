{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a2ULyfpQ2kt"
      },
      "source": [
        "# Underfitting vs. Overfitting\n",
        "\n",
        "Fuente: \n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html \n",
        "\n",
        "Este ejemplo toma como base el ejemplo que pueden ver en el link anterior y demuestra los problemas de subajuste y sobreajuste y cómo podemos usar la regresión lineal con características polinómicas para aproximar funciones no lineales como la funcion coseno. La gráfica muestra la función que queremos aproximar, que es parte de la función coseno. \n",
        "\n",
        "Además, se muestran las muestras de la función real y las aproximaciones de diferentes modelos.Los modelos tienen características polinómicas de diferentes grados. \n",
        "\n",
        "## Underfitting\n",
        "Podemos ver que una función lineal (polinomio con grado 1) no es suficiente para ajustar las muestras de entrenamiento. \n",
        "\n",
        "## Mejor ajuste\n",
        "Un polinomio de grado 4 se aproxima casi perfectamente a la verdadera función. \n",
        "\n",
        "## Overfitting\n",
        "Sin embargo, para grados más altos, el modelo sobreajustará los datos de entrenamiento, es decir, aprenderá el ruido de los datos de entrenamiento. \n",
        "\n",
        "## Evaluacion\n",
        "\n",
        "Evaluamos cuantitativamente el sobreajuste/desajuste mediante el uso de validación cruzada. \n",
        "Calculamos el error cuadrático medio (MSE) en el conjunto de validación, cuanto más alto, menos probable es que el modelo generalice correctamente a partir de los datos de entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi3b_7cJQ0V9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funcion a aproximar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtZOgeY4RCDc"
      },
      "outputs": [],
      "source": [
        "def true_fun(X):\n",
        "    return np.cos(1.5 * np.pi * X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOExs2xFREES"
      },
      "source": [
        "### Parametros para probar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGFIBCGkRGNo"
      },
      "outputs": [],
      "source": [
        "# Semilla \n",
        "np.random.seed(0)\n",
        "\n",
        "# Cantidad de muestras\n",
        "n_samples = 30\n",
        "\n",
        "# Grados de polinomios usados\n",
        "degrees = [1,2,3, 4, 7,15,21]\n",
        "\n",
        "# Multiplicador\n",
        "k = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Genero los datos usados\n",
        "\n",
        "- x: features usados para predecir\n",
        "- y: Valores a predecir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9Sq4X_PRIGu"
      },
      "outputs": [],
      "source": [
        "X = np.sort(np.random.rand(n_samples)) * k \n",
        "y = true_fun(X) + np.random.randn(n_samples) * 0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "aciRa85aR_Zc",
        "outputId": "ec29dc67-2497-4029-e0f2-51572068bbd7"
      },
      "source": [
        "## Plot de los valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "tzyjwnqITaX7",
        "outputId": "859de873-4aa6-442b-bcb8-d788a1ee1052"
      },
      "outputs": [],
      "source": [
        "plt.plot(X, y, color = 'red', label=\"Actual\")\n",
        "plt.plot(X, true_fun(X), label=\"True function\")\n",
        "plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYoezqZNY5yN"
      },
      "source": [
        "### Evaluacion de modelos polinomicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "1MiqcdEIRKEx",
        "outputId": "12a53a15-d00d-4976-af29-239e3071591d"
      },
      "outputs": [],
      "source": [
        "# Tamáño del grafico\n",
        "plt.figure(figsize=(30, 7))\n",
        "\n",
        "# import pandas as pd \n",
        "# df = pd.DataFrame(columns = ['Degrees', 'Mean', 'Stdev'])\n",
        "\n",
        "\n",
        "#itera por la cantidad de polinomios \n",
        "for i in range(len(degrees)):\n",
        "    \n",
        "    ax = plt.subplot(1, len(degrees), i + 1)\n",
        "    plt.setp(ax, xticks=(), yticks=())\n",
        "\n",
        "    #Estas son las transformaciones y el modelo que se aplican a los datos\n",
        "    polynomial_features = PolynomialFeatures(degree=degrees[i],include_bias=False)\n",
        "    linear_regression = LinearRegression()\n",
        "    \n",
        "    #Arma el pipeline con las tuplas que componen las trasnformaciones y el modelo\n",
        "    pipeline = Pipeline(\n",
        "        [(\"polynomial_features\", polynomial_features), \n",
        "         (\"linear_regression\", linear_regression)]\n",
        "    )\n",
        "    \n",
        "    # arma la matriz de entrenamiento\n",
        "    x0 = X[:, np.newaxis]\n",
        "    \n",
        "    #Aplica el pipeline a los datos y entrena el modelo\n",
        "    pipeline.fit(x0, y)\n",
        "\n",
        "    # Evalua el modelo mediante cross_val_score\n",
        "    scores = cross_val_score(pipeline, x0, y,scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "    # Muestra los resultados\n",
        "    X_test = np.linspace(0, k, 100)\n",
        "    \n",
        "    y_poly_pred = pipeline.predict(X_test[:, np.newaxis])\n",
        "    plt.plot(X_test, y_poly_pred, label=\"Model\")\n",
        "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
        "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.xlim((0, k))\n",
        "    plt.ylim((-2, 2))\n",
        "    plt.legend(loc=\"best\")\n",
        "    \n",
        " \n",
        "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(degrees[i], -scores.mean(), scores.std()))\n",
        "    \n",
        "    #df.append(pd.DataFrame([degrees[i],-scores.mean(), scores.std()]).T)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " \n",
        "#print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Underfitting vs. Overfitting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
